{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cfaf5e65-a923-438d-87cc-817a4ac19b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from dgllife.utils import CanonicalAtomFeaturizer, CanonicalBondFeaturizer, mol_to_bigraph\n",
    "import dgl.function as fn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset\n",
    "from dgl.dataloading import GraphDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5e1261d0-dc4f-4436-8bd4-7cbc848e0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load raw data\n",
    "df = pd.read_csv('./RuCHFunctionalizationDataset/dataset.csv')\n",
    "df_DG = pd.read_csv('./RuCHFunctionalizationDataset/DG.csv')\n",
    "df_RX = pd.read_csv('./RuCHFunctionalizationDataset/RX.csv')\n",
    "\n",
    "DG_smiles_list = df['DG'].to_list()\n",
    "RX_smiles_list = df['RX'].to_list()\n",
    "catalyst_smiles_list = df['catalyst'].to_list()\n",
    "sol_smiles_list = df['solvent'].to_list()\n",
    "ligand_smiles_list = df['ligand'].to_list()\n",
    "ad_smiles_list = df['addictive'].to_list()\n",
    "\n",
    "DG_mols_list = []\n",
    "for smi in DG_smiles_list:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    DG_mols_list.append(mol)\n",
    "    \n",
    "train_val_num = len(DG_mols_list)\n",
    "    \n",
    "RX_mols_list = []\n",
    "for smi in RX_smiles_list:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    RX_mols_list.append(mol)\n",
    "\n",
    "DG_mols_list = []\n",
    "for smi in DG_smiles_list:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    DG_mols_list.append(mol)\n",
    "    \n",
    "train_val_num = len(DG_mols_list)\n",
    "    \n",
    "RX_mols_list = []\n",
    "for smi in RX_smiles_list:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    RX_mols_list.append(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d84728c7-38a9-43b5-9dc0-0bc51828dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load target for the classification task\n",
    "target = df['tag'].to_list()\n",
    "target = np.array(target)\n",
    "\n",
    "num = df['number'].to_list()\n",
    "num = np.array(num)\n",
    "num_DG = df['DG_num'].to_list()\n",
    "num_DG = np.array(num_DG)\n",
    "num_RX = df['RX_num'].to_list()\n",
    "num_RX = np.array(num_RX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6bbd97dc-4324-4cda-a624-33082153e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare descriptors\n",
    "node_featurizer = CanonicalAtomFeaturizer(atom_data_field='nfeat')\n",
    "edge_featurizer = CanonicalBondFeaturizer(bond_data_field='efeat')\n",
    "enc = OneHotEncoder(sparse = False)\n",
    "\n",
    "ligand_all = ligand_smiles_list\n",
    "ligand_all = np.array(ligand_all)\n",
    "ligand_all = ligand_all.reshape(-1, 1)\n",
    "l_descriptors_all = enc.fit_transform(ligand_all)\n",
    "l_descriptors = l_descriptors_all\n",
    "l_descriptors = torch.from_numpy(l_descriptors).type(torch.float)\n",
    "l_descriptors_n = l_descriptors.shape[1]\n",
    "\n",
    "catalyst_all = catalyst_smiles_list\n",
    "catalyst_all = np.array(catalyst_all)\n",
    "catalyst_all = catalyst_all.reshape(-1, 1)\n",
    "c_descriptors_all = enc.fit_transform(catalyst_all)\n",
    "c_descriptors = c_descriptors_all\n",
    "c_descriptors = torch.from_numpy(c_descriptors).type(torch.float)\n",
    "c_descriptors_n = c_descriptors.shape[1]\n",
    "\n",
    "sol_all = sol_smiles_list\n",
    "sol_all = np.array(sol_all)\n",
    "sol_all = sol_all.reshape(-1, 1)\n",
    "sol_descriptors_all = enc.fit_transform(sol_all)\n",
    "sol_descriptors = sol_descriptors_all\n",
    "sol_descriptors = torch.from_numpy(sol_descriptors).type(torch.float)\n",
    "sol_descriptors_n = sol_descriptors.shape[1]\n",
    "\n",
    "ad_all = ad_smiles_list\n",
    "ad_all = np.array(ad_all)\n",
    "ad_all = ad_all.reshape(-1, 1)\n",
    "ad_descriptors_all = enc.fit_transform(ad_all)\n",
    "ad_descriptors = ad_descriptors_all\n",
    "ad_descriptors = torch.from_numpy(ad_descriptors).type(torch.float)\n",
    "ad_descriptors_n = ad_descriptors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e8cf495b-13c5-49ae-a743-f31c4b54ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find substituted arenes\n",
    "def ortho_substituted(mol):\n",
    "    mol_no_H = AllChem.RemoveHs(mol)\n",
    "    for idx, atom in enumerate(mol_no_H.GetAtoms()):\n",
    "        if idx == 1 :\n",
    "            if atom.GetDegree() > 2:\n",
    "                return True\n",
    "        elif idx == 5:\n",
    "            if atom.GetDegree() > 2:\n",
    "                return True\n",
    "            \n",
    "def meta_substituted(mol):\n",
    "    mol_no_H = AllChem.RemoveHs(mol)\n",
    "    for idx, atom in enumerate(mol_no_H.GetAtoms()):\n",
    "        if idx == 2 :\n",
    "            if atom.GetDegree() > 2:\n",
    "                return True\n",
    "        elif idx == 4:\n",
    "            if atom.GetDegree() > 2:\n",
    "                return True\n",
    "            \n",
    "\n",
    "ortho_sub_list = []\n",
    "meta_sub_list = []\n",
    "\n",
    "for idx, mol in enumerate(DG_mols_list):\n",
    "    if ortho_substituted(mol) == True:\n",
    "        ortho_sub_list.append(idx)\n",
    "\n",
    "for idx, mol in enumerate(DG_mols_list):\n",
    "    if meta_substituted(mol) == True:\n",
    "        meta_sub_list.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "104e0a26-256d-4fbb-8672-082b525c90b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reaction graphs\n",
    "def make_reaction_graphs(DG_mols_list, RX_mols_list, l_desc, c_desc, sol_desc, ad_desc):\n",
    "    n = 0\n",
    "    DG_graphs = []\n",
    "    RX_graphs = []\n",
    "    ligand_graphs = []\n",
    "    catalyst_graphs = []\n",
    "    solvent_graphs = []\n",
    "    addictive_graphs = []\n",
    "    reaction_graphs = []\n",
    "    v1_graphs = []\n",
    "    v2_graphs = []\n",
    "    decs = []\n",
    "    decs_mp = []\n",
    "\n",
    "    for mol1, mol2 in zip(DG_mols_list, RX_mols_list):\n",
    "        g1 = mol_to_bigraph(mol1,node_featurizer=node_featurizer,edge_featurizer=edge_featurizer)\n",
    "        decs.append(g1.ndata['nfeat'])\n",
    "        DG_graphs.append(g1)\n",
    "        virtual_node_id1 = g1.number_of_nodes()# 获取当前节点数作为新节点ID\n",
    "        g1 = dgl.add_nodes(g1, 1) # 添加一个新节点\n",
    "        g1 = dgl.add_edges(g1,[virtual_node_id1] * (g1.number_of_nodes()-1), list(range(g1.number_of_nodes()-1)))# 将新节点连接到所有节点\n",
    "        g1.update_all(fn.copy_u('nfeat', 'm'), fn.sum('m', 'h1'))##进行消息传递\n",
    "        decs_mp.append(g1.ndata['h1'])\n",
    "        \n",
    "        \n",
    "        g1_ndata_num = g1.ndata['h1'].shape[1]###是74？\n",
    "        g_v1 = dgl.graph((torch.tensor([0]), torch.tensor([0])))###创建虚拟节点1的图\n",
    "        g_v1.ndata['h'] = torch.ones(1, g1_ndata_num)\n",
    "        g_v1_f = g1.ndata['h1'][virtual_node_id1]\n",
    "        g_v1.ndata['h'][0] = g_v1_f\n",
    "        v1_graphs.append(g_v1)\n",
    "        \n",
    "        g2 = mol_to_bigraph(mol2,node_featurizer=node_featurizer,edge_featurizer=edge_featurizer)\n",
    "        RX_graphs.append(g2)\n",
    "        virtual_node_id2 = g2.number_of_nodes()# 获取当前节点数作为新节点ID\n",
    "        g2 = dgl.add_nodes(g2, 1) # 添加一个新节点\n",
    "        g2 = dgl.add_edges(g2,[virtual_node_id2] * (g2.number_of_nodes()-1), list(range(g2.number_of_nodes()-1)))# 将新节点连接到所有节点\n",
    "        g2.update_all(fn.copy_u('nfeat', 'm'), fn.sum('m', 'h2'))##进行消息传递\n",
    "        \n",
    "        \n",
    "        g2_ndata_num = g2.ndata['h2'].shape[1]\n",
    "        g_v2 = dgl.graph((torch.tensor([0]), torch.tensor([0])))###创建虚拟节点2的图\n",
    "        g_v2.ndata['h'] = torch.ones(1, g2_ndata_num)\n",
    "        g_v2_f = g2.ndata['h2'][virtual_node_id2]\n",
    "        g_v2.ndata['h'][0] = g_v2_f\n",
    "        v2_graphs.append(g_v2)\n",
    "    \n",
    "        g_l = dgl.graph((torch.tensor([0]), torch.tensor([0])))###创建ligand的图\n",
    "        g_l.ndata['h'] = torch.ones(1, l_descriptors_n)\n",
    "        g_l.ndata['h'][0] = l_desc[n]\n",
    "        g_l.ndata['h'] = torch.cat([g_l.ndata['h'], torch.zeros((1, g1_ndata_num - l_descriptors_n))], dim=1)###为了后面合并图，将节点特征维度统一\n",
    "        ligand_graphs.append(g_l)\n",
    "        \n",
    "        g_c = dgl.graph((torch.tensor([0]), torch.tensor([0])))###创建cat的图\n",
    "        g_c.ndata['h'] = torch.ones(1, c_descriptors_n)\n",
    "        g_c.ndata['h'][0] = c_desc[n]\n",
    "        g_c.ndata['h'] = torch.cat([g_c.ndata['h'], torch.zeros((1, g1_ndata_num - c_descriptors_n))], dim=1)###为了后面合并图，将节点特征维度统一\n",
    "        catalyst_graphs.append(g_c)\n",
    "        \n",
    "        g_s = dgl.graph((torch.tensor([0]), torch.tensor([0])))###创建sol的图\n",
    "        g_s.ndata['h'] = torch.ones(1, sol_descriptors_n)\n",
    "        g_s.ndata['h'][0] = sol_desc[n]\n",
    "        g_s.ndata['h'] = torch.cat([g_s.ndata['h'], torch.zeros((1, g1_ndata_num - sol_descriptors_n))], dim=1)###为了后面合并图，将节点特征维度统一\n",
    "        solvent_graphs.append(g_s)\n",
    "        \n",
    "        g_ad = dgl.graph((torch.tensor([0]), torch.tensor([0])))###创建ad的图\n",
    "        g_ad.ndata['h'] = torch.ones(1, ad_descriptors_n)\n",
    "        g_ad.ndata['h'][0] = ad_desc[n]\n",
    "        g_ad.ndata['h'] = torch.cat([g_ad.ndata['h'], torch.zeros((1, g1_ndata_num - ad_descriptors_n))], dim=1)###为了后面合并图，将节点特征维度统一\n",
    "        addictive_graphs.append(g_ad)\n",
    "        \n",
    "        g_r = dgl.batch([g_c, g_l, g_s, g_ad])##合并图\n",
    "        g_r.add_edges([0]*3,range(1,4))###所有节点连边\n",
    "        g_r.add_edges([1]*3,[0,2,3])###所有节点连边\n",
    "        g_r.add_edges([2]*3,[0,1,3])###所有节点连边\n",
    "        g_r.add_edges([3]*3,[0,1,2])###所有节点连边\n",
    "        #g_r.add_edges([4]*4,[0,1,2,3])###所有节点连边\n",
    "        #g_r.add_edges([5]*5,[0,1,2,3,4])###所有节点连边\n",
    "        reaction_graphs.append(g_r)\n",
    "        \n",
    "        n = n+1\n",
    "    return v1_graphs, v2_graphs, reaction_graphs, decs, decs_mp, DG_graphs, RX_graphs\n",
    "   \n",
    "v1_graphs, v2_graphs, reaction_graphs, decs, decs_mp, DG_graphs, RX_graphs = make_reaction_graphs(DG_mols_list, RX_mols_list, l_descriptors, c_descriptors, sol_descriptors, ad_descriptors)\n",
    "reaction_graphs = np.array(reaction_graphs)\n",
    "v1_graphs = np.array(v1_graphs)\n",
    "v2_graphs = np.array(v2_graphs)\n",
    "DG_graphs = np.array(DG_graphs)\n",
    "RX_graphs = np.array(RX_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6907ee91-5dd8-4a19-918f-168629641c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataloader\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, graph_list, label_list, num_list):\n",
    "        self.graph_list = graph_list\n",
    "        self.label_list = label_list\n",
    "        self.num_list = num_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.graph_list)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graph_list[idx]\n",
    "        labels = self.label_list[idx]\n",
    "        num = self.num_list[idx]\n",
    "        return graph, labels, num\n",
    "\n",
    "target = torch.tensor(target, dtype=torch.long)\n",
    "num = torch.tensor(num, dtype=torch.long)\n",
    "dataset = GraphDataset(reaction_graphs, target, num)\n",
    "\n",
    "dataloader = GraphDataLoader(\n",
    "    dataset,\n",
    "    batch_size=30,\n",
    "    drop_last=False,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "13fd262e-749c-4883-9486-2a46b9f94df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single-task classifier and evaluate function\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, n_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = dglnn.GraphConv(in_dim, hidden_dim)\n",
    "        self.conv2 = dglnn.GraphConv(hidden_dim, hidden_dim)\n",
    "        self.classify = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # 应用图卷积和激活函数\n",
    "        h = F.relu(self.conv1(g, h))\n",
    "        h = F.relu(self.conv2(g, h))\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # 使用平均读出计算图表示\n",
    "            hg = dgl.mean_nodes(g, 'h')\n",
    "            classify_output = self.classify(hg)\n",
    "            return classify_output, hg\n",
    "        \n",
    "def evaluate(dataloader, model, o_sub_list, m_sub_list):###验证模型精确度函数\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    total_correct = 0\n",
    "    num_list = []\n",
    "    for batched_graph, labels, num in dataloader:\n",
    "        feat = batched_graph.ndata['h']\n",
    "        total += len(labels)\n",
    "        logits, hg = model(batched_graph, feat)\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            if num[i] in o_sub_list:\n",
    "                if labels[i] == predicted[i]:\n",
    "                    total_correct += 1\n",
    "                if labels[i] == 4 and predicted[i] == 0:\n",
    "                    total_correct += 1\n",
    "                    predicted[i] = 4\n",
    "            elif num[i] in m_sub_list:\n",
    "                if labels[i] == predicted[i]:\n",
    "                    total_correct += 1\n",
    "                if labels[i] == 4 and predicted[i] == 0:\n",
    "                    total_correct += 1\n",
    "                    predicted[i] = 4\n",
    "                if labels[i] == 3 and predicted[i] == 1:\n",
    "                    total_correct += 1\n",
    "                    predicted[i] = 3\n",
    "            else:\n",
    "                if labels[i] == 0 and predicted[i] == 0:\n",
    "                    total_correct += 1\n",
    "                elif labels[i] == 0 and predicted[i] == 4:\n",
    "                    total_correct += 1\n",
    "                elif labels[i] == 1 and predicted[i] == 1:\n",
    "                    total_correct += 1\n",
    "                elif labels[i] == 1 and predicted[i] == 3:\n",
    "                    total_correct += 1\n",
    "                elif labels[i] == 2 and predicted[i] == 2:\n",
    "                    total_correct += 1\n",
    "        num_list.append(num)    \n",
    "    acc = 1.0 * total_correct / total\n",
    "    return acc, predicted, labels, hg, num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "370b1d32-1313-463c-a782-74e88ff7de9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 00001 | Epoch 00199 | Loss 0.1140 | Train Acc. 0.9130 | Validation Acc. 0.7308 \n",
      "Fold 00002 | Epoch 00199 | Loss 0.3363 | Train Acc. 0.8826 | Validation Acc. 0.8846 \n",
      "Fold 00003 | Epoch 00199 | Loss 0.1725 | Train Acc. 0.9043 | Validation Acc. 0.8462 \n",
      "Fold 00004 | Epoch 00199 | Loss 0.1677 | Train Acc. 0.8913 | Validation Acc. 0.8846 \n",
      "Fold 00005 | Epoch 00199 | Loss 0.2780 | Train Acc. 0.9043 | Validation Acc. 0.9231 \n",
      "Fold 00006 | Epoch 00199 | Loss 0.3094 | Train Acc. 0.8913 | Validation Acc. 0.8846 \n",
      "Fold 00007 | Epoch 00199 | Loss 0.5308 | Train Acc. 0.9004 | Validation Acc. 0.8400 \n",
      "Fold 00008 | Epoch 00199 | Loss 0.2684 | Train Acc. 0.8961 | Validation Acc. 1.0000 \n",
      "Fold 00009 | Epoch 00199 | Loss 0.2308 | Train Acc. 0.9048 | Validation Acc. 0.8000 \n",
      "Fold 00010 | Epoch 00199 | Loss 0.0175 | Train Acc. 0.9048 | Validation Acc. 0.9200 \n",
      "Accuracy after CV: 0.8713846153846154\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "fold_num = 1\n",
    "all_acc_list = []\n",
    "target_list_cm = []\n",
    "pred_list_cm = []\n",
    "hg_all = torch.empty(0)\n",
    "h3_all = torch.empty(0)\n",
    "num_val_end = []\n",
    "wrong_list = []\n",
    "\n",
    "for train_indices, val_indices in kf.split(dataset):\n",
    "    \n",
    "    train_dataset = [dataset[i] for i in train_indices]\n",
    "    val_dataset = [dataset[i] for i in val_indices]\n",
    "    \n",
    "    train_loader = GraphDataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=30,\n",
    "        drop_last=False,\n",
    "        shuffle=True)\n",
    "    \n",
    "    val_loader = GraphDataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=30,\n",
    "        drop_last=False,\n",
    "        shuffle=True)\n",
    "    \n",
    "    \n",
    "    model = Classifier(74, 74, 5)\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "    train_acc_list = []\n",
    "    valid_acc_list = [0.0]\n",
    "    loss_list = []\n",
    "    predicted_val_list = []\n",
    "    labels_val_list = []\n",
    "    for epoch in range(200):\n",
    "        for graph, labels, num in train_loader:\n",
    "            feats = graph.ndata['h']\n",
    "            logits, hg = model(graph, feats)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        train_acc, predicted_train, labels_train, hg_t, num_train = evaluate(train_loader, model, ortho_sub_list, meta_sub_list)\n",
    "        train_acc_list.append(train_acc)\n",
    "        valid_acc, predicted_val, labels_val, hg_v, num_val = evaluate(val_loader, model, ortho_sub_list, meta_sub_list)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "        predicted_val_list.append(predicted_val)\n",
    "        labels_val_list.append(labels_val)\n",
    "        loss1 = loss\n",
    "        loss1 = loss1.detach()\n",
    "        loss1 = loss1.numpy()\n",
    "        loss_list.append(loss1)\n",
    "        if epoch == 199:\n",
    "            hg_all =torch.cat((hg_all, hg_v), dim=0)\n",
    "        if max(valid_acc_list[:-1]) < valid_acc_list[-1]:\n",
    "            h3_all_m = torch.empty(0)\n",
    "            num_val_end_m = torch.empty(0)\n",
    "            target_max = []\n",
    "            pred_max = []\n",
    "            \n",
    "            h3_all_m =torch.cat((h3_all_m, hg_v), dim=0)\n",
    "            num_val_end_m = torch.cat((num_val_end_m, num_val[0]), dim=0)\n",
    "            target_max.append(labels_val)\n",
    "            pred_max.append(predicted_val)\n",
    "            \n",
    "    h3_all =torch.cat((h3_all_m, h3_all), dim=0)    \n",
    "    \n",
    "    print(\n",
    "        \"Fold {:05d} | Epoch {:05d} | Loss {:.4f} | Train Acc. {:.4f} | Validation Acc. {:.4f} \".format(\n",
    "        fold_num, epoch, loss , max(train_acc_list), max(valid_acc_list))\n",
    "        )\n",
    "    fold_num += 1\n",
    "    all_acc_list.append(max(valid_acc_list))\n",
    "    \n",
    "    temp1 = labels_val_list[-1].tolist()\n",
    "    temp2 = predicted_val_list[-1].tolist()\n",
    "    target_list_cm.extend(temp1)\n",
    "    pred_list_cm.extend(temp2)\n",
    "    num_val_end.append(num_val_end_m)\n",
    "    \n",
    "average_accuracy = np.mean(all_acc_list)\n",
    "print(\"Accuracy after CV:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde87f56-38ee-4a35-875e-611156254d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
